# Wildberries products parser
### Возможности
- Парсинг подкатегорий продуктов
- Импорт полученной информации в csv

------------


###Установка и настройка
1. Клонируйте репозиторий
`git clone https://github.com/devShev/wildberries-products-parser.git`

2.  Выберите необходимую подкатегорию в браузере

      ![](https://i.ibb.co/J78b5c2/2022-10-13-203956.png)

3.  Нажмите F12 для входа в панель разработчика, перейдите на вкладку "Сеть" ("Network") и обновите страницу

      ![](https://i.ibb.co/K6d9pbz/2022-10-13-204236.png)

4. В строке поиске введите "subject"

      ![](https://i.ibb.co/g3WnMcR/2022-10-13-204402.png)

5. В полученных результатах необходимо найти запрос который начинается на

      > catalog?__tmp

6. Нажимаем по запросу левой кнопкой мыши и в появившемся боковом окне полностью копируем строку запроса

      ![](https://i.ibb.co/yyvy9pT/2022-10-13-204826.png)

7. Переходим в директорию проекта, открываем файл ".env" и вставляет нашу строку в URL

      ![](https://i.ibb.co/Q6gh7Wq/2022-10-13-205048.png)

***Настройка завершена***

------------

### Использование
Для использования необходимо создать экземпляр класса Parser и передать в него наш URL

`parser = Parser(url)`

##### Методы парсера

- parse() - парсинг страницы
- save_csv() - сохранить данные в csv файл
- load_csv() - загрузить данные из csv файла в парсер
- print_data() - вывод информации внутри парсера
- run() - запуск цикла парсинга (по дефолту цикл отключен)
- parse_page() - распарсить конкретную страницу
- set_max_page() - установить максимальное количество страниц при парсинге


### **save_csv(filepath: str), load_csv(filepath: str)**
- Могут принимать на вход строку - путь/название файла

### **parse(all_pages: bool)**
- Принимает необязательный параметр *all_pages* (bool). Позволяет парсить множество страниц (стандратное значение - False)

### **parse_page(page: int)**
- Принимает обязательный парметр *page* (int). Позволяет распарсить конкретную страницу

### **set_max_page(page: int)**
- Принимает обязательный параметр *page* (int). Позволяет установить максимальное количество страниц для парсинга (стандартное значение - 100)

### **run(all_pages: bool, export_csv: bool, repeat: bool, timer: int)**
- Запускает цикл парсинга
- Принимает необязательный параметр *all_pages* (bool). Для парсинга множества страниц
- Принимает необязательный аргумент *export_csv* (bool). Для импорта данных в csv (стандартное значение - False)
- Принимает необязательный параметр *repeat* (bool). Для запуска бесконечного цикла. В данном случае будут показываться только изменения данных. При установке параметра *export_csv* в значение True изменения в консоли отображаться не будут (стандартное значение - False, а значит, что цикл необходимо включать вручную)
- Принимает необязательный параметр *timer* (int). Для установки времени обновления данных (в секундах) (стандартное значение - 60)

------------


### Пример кода

```python
import os

from src.parser import Parser


url = os.environ.get("URL")

parser = Parser(url)

parser.parse(all_pages=True)  # Парсинг всех страниц (от 1 до MAX)
parser.print_data()  # Вывод полученной информации в терминал
parser.save_csv()  # Сохранение информации в csv

```
